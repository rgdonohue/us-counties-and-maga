{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Acquisition\n",
    "\n",
    "This notebook handles downloading and caching all required datasets for the pain-Trump correlation analysis.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "### Electoral Data\n",
    "- County presidential returns (2016, 2020, 2024) from MIT Election Lab\n",
    "\n",
    "### Pain/Distress Proxies\n",
    "- CDC WONDER mortality data (overdose, suicide rates)\n",
    "- CDC opioid dispensing rates\n",
    "- CDC PLACES (frequent physical distress, arthritis)\n",
    "- USALEEP life expectancy estimates\n",
    "- County Health Rankings indicators\n",
    "\n",
    "### Contextual/Control Variables\n",
    "- USDA Rural-Urban Continuum Codes\n",
    "- USDA County Typology Codes\n",
    "- Census ACS 5-year estimates\n",
    "- SSA OASDI/SSI disability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import zipfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup paths\n",
    "project_root = Path.cwd().parent\n",
    "data_raw = project_root / 'data' / 'raw'\n",
    "data_processed = project_root / 'data' / 'processed'\n",
    "data_external = project_root / 'data' / 'external'\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(f\"Data will be saved to: {data_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. County Boundaries (Shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_county_boundaries():\n",
    "    \"\"\"Download US county boundaries from Census Bureau\"\"\"\n",
    "    url = \"https://www2.census.gov/geo/tiger/TIGER2023/COUNTY/tl_2023_us_county.zip\"\n",
    "    output_dir = data_raw / 'shapefiles'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    zip_path = output_dir / 'counties.zip'\n",
    "    \n",
    "    if not zip_path.exists():\n",
    "        logger.info(\"Downloading county boundaries...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(zip_path, 'wb') as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Extract\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_dir)\n",
    "        logger.info(\"County boundaries downloaded and extracted\")\n",
    "    else:\n",
    "        logger.info(\"County boundaries already exist\")\n",
    "    \n",
    "    # Load and preview\n",
    "    counties = gpd.read_file(output_dir / 'tl_2023_us_county.shp')\n",
    "    logger.info(f\"Loaded {len(counties)} counties\")\n",
    "    return counties\n",
    "\n",
    "counties_gdf = download_county_boundaries()\n",
    "counties_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Electoral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_election_data():\n",
    "    \"\"\"Download county-level presidential election results\"\"\"\n",
    "    \n",
    "    # MIT Election Lab data URLs (these are examples - verify current URLs)\n",
    "    election_urls = {\n",
    "        '2016': 'https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/VOQCHQ/HEIJCQ',\n",
    "        '2020': 'https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/VOQCHQ/NJTQLE'\n",
    "    }\n",
    "    \n",
    "    election_dir = data_raw / 'elections'\n",
    "    election_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    election_data = {}\n",
    "    \n",
    "    for year, url in election_urls.items():\n",
    "        file_path = election_dir / f'county_presidential_{year}.csv'\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            logger.info(f\"Downloading {year} election data...\")\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            logger.info(f\"{year} election data downloaded\")\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path)\n",
    "        election_data[year] = df\n",
    "        logger.info(f\"{year}: {len(df)} records\")\n",
    "    \n",
    "    return election_data\n",
    "\n",
    "# Note: You'll need to verify and update these URLs\n",
    "# election_data = download_election_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CDC WONDER Mortality Data\n",
    "\n",
    "Note: CDC WONDER requires interactive querying. We'll set up the structure for manual downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cdc_wonder_queries():\n",
    "    \"\"\"Generate query parameters for CDC WONDER\"\"\"\n",
    "    \n",
    "    queries = {\n",
    "        'overdose': {\n",
    "            'cause': 'Drug poisonings (overdose) Unintentional (X40-X44)',\n",
    "            'years': ['2013-2016', '2017-2020'],\n",
    "            'group_by': ['County', 'Year'],\n",
    "            'measures': ['Deaths', 'Population', 'Age-Adjusted Rate']\n",
    "        },\n",
    "        'suicide': {\n",
    "            'cause': 'Intentional self-harm (suicide) (X60-X84, Y87.0)',\n",
    "            'years': ['2013-2016', '2017-2020'],\n",
    "            'group_by': ['County', 'Year'],\n",
    "            'measures': ['Deaths', 'Population', 'Age-Adjusted Rate']\n",
    "        },\n",
    "        'despair': {\n",
    "            'cause': 'Deaths of Despair (drug, alcohol, suicide)',\n",
    "            'years': ['2013-2016', '2017-2020'],\n",
    "            'group_by': ['County', 'Year'],\n",
    "            'measures': ['Deaths', 'Population', 'Age-Adjusted Rate']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save query instructions\n",
    "    wonder_dir = data_raw / 'cdc_wonder'\n",
    "    wonder_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    instructions = [\n",
    "        \"CDC WONDER Query Instructions:\",\n",
    "        \"1. Go to https://wonder.cdc.gov/mcd.html\",\n",
    "        \"2. Use the following parameters for each query:\",\n",
    "        \"\"\n",
    "    ]\n",
    "    \n",
    "    for name, params in queries.items():\n",
    "        instructions.append(f\"Query: {name}\")\n",
    "        instructions.append(f\"  - Cause: {params['cause']}\")\n",
    "        instructions.append(f\"  - Years: {params['years']}\")\n",
    "        instructions.append(f\"  - Group by: {params['group_by']}\")\n",
    "        instructions.append(f\"  - Export as: Tab-delimited\")\n",
    "        instructions.append(f\"  - Save to: {wonder_dir / f'{name}_{{year_range}}.txt'}\")\n",
    "        instructions.append(\"\")\n",
    "    \n",
    "    with open(wonder_dir / 'query_instructions.txt', 'w') as f:\n",
    "        f.write('\\n'.join(instructions))\n",
    "    \n",
    "    logger.info(f\"CDC WONDER query instructions saved to {wonder_dir / 'query_instructions.txt'}\")\n",
    "    return queries\n",
    "\n",
    "cdc_queries = prepare_cdc_wonder_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CDC PLACES Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cdc_places():\n",
    "    \"\"\"Download CDC PLACES county-level health data\"\"\"\n",
    "    \n",
    "    # PLACES data URL (2023 release)\n",
    "    url = \"https://data.cdc.gov/api/views/swc5-untb/rows.csv?accessType=DOWNLOAD\"\n",
    "    \n",
    "    places_dir = data_raw / 'cdc_places'\n",
    "    places_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = places_dir / 'places_county_2023.csv'\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        logger.info(\"Downloading CDC PLACES data...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
    "                f.write(chunk)\n",
    "        logger.info(\"CDC PLACES data downloaded\")\n",
    "    else:\n",
    "        logger.info(\"CDC PLACES data already exists\")\n",
    "    \n",
    "    # Load and filter relevant columns\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    # Filter for pain-related measures\n",
    "    pain_measures = [\n",
    "        'ARTHRITIS',  # Arthritis among adults\n",
    "        'PHLTH',      # Physical health not good for >=14 days\n",
    "        'DISABILITY', # Any disability\n",
    "        'DEPRESSION'  # Depression\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"Loaded {len(df)} records with {df.columns.tolist()[:5]}... columns\")\n",
    "    return df\n",
    "\n",
    "# places_df = download_cdc_places()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Opioid Dispensing Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_opioid_dispensing():\n",
    "    \"\"\"Download CDC opioid dispensing rate data\"\"\"\n",
    "    \n",
    "    opioid_dir = data_raw / 'opioids'\n",
    "    opioid_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Years available: 2006-2021\n",
    "    years = range(2015, 2022)\n",
    "    \n",
    "    instructions = [\n",
    "        \"CDC Opioid Dispensing Rate Data:\",\n",
    "        \"Download from: https://www.cdc.gov/overdose-prevention/data-research/facts-stats/opioid-dispensing-rate-maps.html\",\n",
    "        \"\",\n",
    "        \"Files to download:\",\n",
    "    ]\n",
    "    \n",
    "    for year in years:\n",
    "        instructions.append(f\"  - {year} County Opioid Dispensing Rates\")\n",
    "        instructions.append(f\"    Save to: {opioid_dir / f'opioid_dispensing_{year}.xlsx'}\")\n",
    "    \n",
    "    with open(opioid_dir / 'download_instructions.txt', 'w') as f:\n",
    "        f.write('\\n'.join(instructions))\n",
    "    \n",
    "    logger.info(f\"Opioid data download instructions saved to {opioid_dir}\")\n",
    "\n",
    "download_opioid_dispensing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. USDA Rural-Urban Continuum Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_rucc_codes():\n",
    "    \"\"\"Download USDA Rural-Urban Continuum Codes\"\"\"\n",
    "    \n",
    "    url = \"https://www.ers.usda.gov/webdocs/DataFiles/53251/ruralurbancodes2023.xlsx?v=4833.5\"\n",
    "    \n",
    "    usda_dir = data_raw / 'usda'\n",
    "    usda_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = usda_dir / 'rucc_2023.xlsx'\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        logger.info(\"Downloading RUCC codes...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        logger.info(\"RUCC codes downloaded\")\n",
    "    else:\n",
    "        logger.info(\"RUCC codes already exist\")\n",
    "    \n",
    "    # Load and preview\n",
    "    df = pd.read_excel(file_path)\n",
    "    logger.info(f\"Loaded {len(df)} counties with RUCC codes\")\n",
    "    return df\n",
    "\n",
    "# rucc_df = download_rucc_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Census ACS Data\n",
    "\n",
    "Using the Census API for American Community Survey 5-year estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_census_api():\n",
    "    \"\"\"Setup Census API access and define variables to fetch\"\"\"\n",
    "    \n",
    "    # Variables to fetch from ACS 5-year estimates\n",
    "    acs_variables = {\n",
    "        'B01003_001E': 'total_population',\n",
    "        'B25077_001E': 'median_home_value',\n",
    "        'B19013_001E': 'median_household_income',\n",
    "        'B15003_022E': 'bachelors_degree',\n",
    "        'B15003_023E': 'masters_degree',\n",
    "        'B15003_024E': 'professional_degree',\n",
    "        'B15003_025E': 'doctorate_degree',\n",
    "        'B01001_020E': 'male_65_66',\n",
    "        'B01001_021E': 'male_67_69',\n",
    "        'B01001_022E': 'male_70_74',\n",
    "        'B01001_023E': 'male_75_79',\n",
    "        'B01001_024E': 'male_80_84',\n",
    "        'B01001_025E': 'male_85_plus',\n",
    "        'B01001_044E': 'female_65_66',\n",
    "        'B01001_045E': 'female_67_69',\n",
    "        'B01001_046E': 'female_70_74',\n",
    "        'B01001_047E': 'female_75_79',\n",
    "        'B01001_048E': 'female_80_84',\n",
    "        'B01001_049E': 'female_85_plus',\n",
    "        'B02001_002E': 'white_alone',\n",
    "        'B02001_003E': 'black_alone',\n",
    "        'B03002_012E': 'hispanic_latino',\n",
    "        'B23025_005E': 'unemployed',\n",
    "        'B23025_002E': 'labor_force'\n",
    "    }\n",
    "    \n",
    "    census_dir = data_raw / 'census'\n",
    "    census_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save variable definitions\n",
    "    with open(census_dir / 'acs_variables.json', 'w') as f:\n",
    "        json.dump(acs_variables, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Census ACS variable definitions saved to {census_dir}\")\n",
    "    \n",
    "    # Note: You'll need a Census API key\n",
    "    # Get one at: https://api.census.gov/data/key_signup.html\n",
    "    api_key = os.getenv('CENSUS_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        logger.warning(\"No Census API key found. Add CENSUS_API_KEY to your .env file\")\n",
    "        logger.info(\"Get a key at: https://api.census.gov/data/key_signup.html\")\n",
    "    \n",
    "    return acs_variables\n",
    "\n",
    "acs_vars = setup_census_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Download Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_summary():\n",
    "    \"\"\"Create a summary of all data sources and their status\"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'data_sources': {\n",
    "            'county_boundaries': {\n",
    "                'source': 'Census TIGER',\n",
    "                'url': 'https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html',\n",
    "                'status': 'automated',\n",
    "                'path': str(data_raw / 'shapefiles')\n",
    "            },\n",
    "            'elections': {\n",
    "                'source': 'MIT Election Lab',\n",
    "                'url': 'https://electionlab.mit.edu/data',\n",
    "                'status': 'manual_required',\n",
    "                'path': str(data_raw / 'elections')\n",
    "            },\n",
    "            'cdc_wonder': {\n",
    "                'source': 'CDC WONDER',\n",
    "                'url': 'https://wonder.cdc.gov/',\n",
    "                'status': 'manual_required',\n",
    "                'path': str(data_raw / 'cdc_wonder')\n",
    "            },\n",
    "            'cdc_places': {\n",
    "                'source': 'CDC PLACES',\n",
    "                'url': 'https://www.cdc.gov/places/',\n",
    "                'status': 'automated',\n",
    "                'path': str(data_raw / 'cdc_places')\n",
    "            },\n",
    "            'opioid_dispensing': {\n",
    "                'source': 'CDC Opioid Data',\n",
    "                'url': 'https://www.cdc.gov/overdose-prevention/',\n",
    "                'status': 'manual_required',\n",
    "                'path': str(data_raw / 'opioids')\n",
    "            },\n",
    "            'rucc': {\n",
    "                'source': 'USDA ERS',\n",
    "                'url': 'https://www.ers.usda.gov/',\n",
    "                'status': 'automated',\n",
    "                'path': str(data_raw / 'usda')\n",
    "            },\n",
    "            'census_acs': {\n",
    "                'source': 'Census ACS',\n",
    "                'url': 'https://www.census.gov/programs-surveys/acs',\n",
    "                'status': 'api_required',\n",
    "                'path': str(data_raw / 'census')\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(project_root / 'data_acquisition_status.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    logger.info(\"Data acquisition summary created\")\n",
    "    \n",
    "    # Print status\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA ACQUISITION STATUS\")\n",
    "    print(\"=\"*50)\n",
    "    for source, info in summary['data_sources'].items():\n",
    "        status_emoji = \"✅\" if info['status'] == 'automated' else \"⚠️\"\n",
    "        print(f\"{status_emoji} {source:20} - {info['status']}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "summary = create_download_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}