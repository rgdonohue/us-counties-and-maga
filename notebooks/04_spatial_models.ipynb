{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Spatial Regression Models\n",
    "\n",
    "This notebook fits spatial regression models to examine the relationship between pain/distress metrics and Trump voting, accounting for spatial dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Spatial regression\n",
    "import libpysal\n",
    "from libpysal.weights import Queen\n",
    "import spreg\n",
    "from spreg import OLS, ML_Lag, ML_Error, GM_Lag\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Setup\n",
    "project_root = Path.cwd().parent\n",
    "data_processed = project_root / 'data' / 'processed'\n",
    "reports = project_root / 'reports'\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Prepare Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "gdf = gpd.read_file(data_processed / 'counties_analysis.geojson')\n",
    "\n",
    "# Drop missing values for key variables\n",
    "model_vars = [\n",
    "    'trump_share_2016',\n",
    "    'freq_phys_distress_pct',\n",
    "    'od_1316_rate',\n",
    "    'rucc',\n",
    "    'ba_plus_pct',\n",
    "    'median_income',\n",
    "    'unemp_rate',\n",
    "    'pct_65plus',\n",
    "    'pct_nonwhite'\n",
    "]\n",
    "\n",
    "# Create analysis dataset\n",
    "df_model = gdf[model_vars + ['fips', 'NAME', 'geometry']].dropna()\n",
    "print(f\"Analysis sample: {len(df_model)} counties (from {len(gdf)} total)\")\n",
    "\n",
    "# Standardize variables for easier interpretation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "continuous_vars = ['freq_phys_distress_pct', 'od_1316_rate', 'ba_plus_pct', \n",
    "                   'median_income', 'unemp_rate', 'pct_65plus', 'pct_nonwhite']\n",
    "\n",
    "df_model_std = df_model.copy()\n",
    "df_model_std[continuous_vars] = scaler.fit_transform(df_model[continuous_vars])\n",
    "\n",
    "print(\"\\nStandardized variables (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Spatial Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Queen contiguity weights\n",
    "w = Queen.from_dataframe(df_model_std, use_index=False)\n",
    "w.transform = 'r'  # Row-standardize\n",
    "\n",
    "print(f\"Spatial weights summary:\")\n",
    "print(f\"  Number of observations: {w.n}\")\n",
    "print(f\"  Average neighbors: {w.mean_neighbors:.2f}\")\n",
    "print(f\"  Min neighbors: {w.min_neighbors}\")\n",
    "print(f\"  Max neighbors: {w.max_neighbors}\")\n",
    "\n",
    "# Check for islands\n",
    "if len(w.islands) > 0:\n",
    "    print(f\"\\nWarning: {len(w.islands)} islands detected\")\n",
    "    # Remove islands for model stability\n",
    "    df_model_std = df_model_std[~df_model_std.index.isin(w.islands)]\n",
    "    w = Queen.from_dataframe(df_model_std, use_index=False)\n",
    "    w.transform = 'r'\n",
    "    print(f\"After removing islands: {len(df_model_std)} counties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OLS Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for spreg\n",
    "y = df_model_std[['trump_share_2016']].values\n",
    "y_name = 'trump_share_2016'\n",
    "\n",
    "# Model 1: Physical distress as main predictor\n",
    "X1 = df_model_std[[\n",
    "    'freq_phys_distress_pct',\n",
    "    'rucc',\n",
    "    'ba_plus_pct',\n",
    "    'median_income',\n",
    "    'unemp_rate',\n",
    "    'pct_65plus',\n",
    "    'pct_nonwhite'\n",
    "]].values\n",
    "\n",
    "X1_names = [\n",
    "    'const',\n",
    "    'phys_distress',\n",
    "    'rucc',\n",
    "    'ba_plus',\n",
    "    'income',\n",
    "    'unemploy',\n",
    "    'age_65plus',\n",
    "    'nonwhite'\n",
    "]\n",
    "\n",
    "# Fit OLS model\n",
    "ols1 = OLS(y, X1, w=w, name_y=y_name, name_x=X1_names, \n",
    "           name_w='queen', name_ds='counties')\n",
    "\n",
    "print(ols1.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_diagnostics(model):\n",
    "    \"\"\"Extract and display spatial diagnostics from OLS model\"\"\"\n",
    "    \n",
    "    print(\"\\nSPATIAL DIAGNOSTICS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Moran's I of residuals\n",
    "    print(f\"Moran's I (residuals): {model.moran_res[0]:.4f}\")\n",
    "    print(f\"  z-score: {model.moran_res[1]:.4f}\")\n",
    "    print(f\"  p-value: {model.moran_res[2]:.4f}\")\n",
    "    \n",
    "    print(\"\\nLagrange Multiplier Tests:\")\n",
    "    print(f\"LM Lag:\")\n",
    "    print(f\"  Statistic: {model.lm_lag[0]:.4f}\")\n",
    "    print(f\"  p-value: {model.lm_lag[1]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nLM Error:\")\n",
    "    print(f\"  Statistic: {model.lm_error[0]:.4f}\")\n",
    "    print(f\"  p-value: {model.lm_error[1]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nRobust LM Lag:\")\n",
    "    print(f\"  Statistic: {model.rlm_lag[0]:.4f}\")\n",
    "    print(f\"  p-value: {model.rlm_lag[1]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nRobust LM Error:\")\n",
    "    print(f\"  Statistic: {model.rlm_error[0]:.4f}\")\n",
    "    print(f\"  p-value: {model.rlm_error[1]:.4f}\")\n",
    "    \n",
    "    # Decision rule\n",
    "    print(\"\\nMODEL SELECTION GUIDANCE:\")\n",
    "    if model.lm_lag[1] < 0.05 and model.lm_error[1] >= 0.05:\n",
    "        print(\"→ Use Spatial Lag Model\")\n",
    "    elif model.lm_error[1] < 0.05 and model.lm_lag[1] >= 0.05:\n",
    "        print(\"→ Use Spatial Error Model\")\n",
    "    elif model.lm_lag[1] < 0.05 and model.lm_error[1] < 0.05:\n",
    "        # Both significant, use robust tests\n",
    "        if model.rlm_lag[1] < model.rlm_error[1]:\n",
    "            print(\"→ Use Spatial Lag Model (based on robust tests)\")\n",
    "        else:\n",
    "            print(\"→ Use Spatial Error Model (based on robust tests)\")\n",
    "    else:\n",
    "        print(\"→ No significant spatial dependence, OLS may be adequate\")\n",
    "\n",
    "spatial_diagnostics(ols1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatial Lag Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Spatial Lag Model\n",
    "lag1 = ML_Lag(y, X1, w=w, name_y=y_name, name_x=X1_names,\n",
    "              name_w='queen', name_ds='counties')\n",
    "\n",
    "print(lag1.summary)\n",
    "\n",
    "# Extract key results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY RESULTS - SPATIAL LAG MODEL\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Spatial lag coefficient (ρ): {lag1.rho:.4f}\")\n",
    "print(f\"Physical distress coefficient: {lag1.betas[1][0]:.4f}\")\n",
    "print(f\"  Standard error: {lag1.std_err[1]:.4f}\")\n",
    "print(f\"  z-value: {lag1.z_stat[1][0]:.4f}\")\n",
    "print(f\"  p-value: {lag1.z_stat[1][1]:.4f}\")\n",
    "print(f\"\\nPseudo R²: {lag1.pr2:.4f}\")\n",
    "print(f\"Log-likelihood: {lag1.logll:.2f}\")\n",
    "print(f\"AIC: {lag1.aic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Spatial Error Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Spatial Error Model\n",
    "error1 = ML_Error(y, X1, w=w, name_y=y_name, name_x=X1_names,\n",
    "                  name_w='queen', name_ds='counties')\n",
    "\n",
    "print(error1.summary)\n",
    "\n",
    "# Extract key results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY RESULTS - SPATIAL ERROR MODEL\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Spatial error coefficient (λ): {error1.lam:.4f}\")\n",
    "print(f\"Physical distress coefficient: {error1.betas[1][0]:.4f}\")\n",
    "print(f\"  Standard error: {error1.std_err[1]:.4f}\")\n",
    "print(f\"  z-value: {error1.z_stat[1][0]:.4f}\")\n",
    "print(f\"  p-value: {error1.z_stat[1][1]:.4f}\")\n",
    "print(f\"\\nPseudo R²: {error1.pr2:.4f}\")\n",
    "print(f\"Log-likelihood: {error1.logll:.2f}\")\n",
    "print(f\"AIC: {error1.aic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(ols_model, lag_model, error_model):\n",
    "    \"\"\"Compare OLS, spatial lag, and spatial error models\"\"\"\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    comparison = pd.DataFrame({\n",
    "        'OLS': [\n",
    "            ols_model.r2,\n",
    "            ols_model.logll,\n",
    "            ols_model.aic,\n",
    "            ols_model.schwarz,\n",
    "            ols_model.betas[1][0],\n",
    "            ols_model.std_err[1],\n",
    "            np.nan,\n",
    "            np.nan\n",
    "        ],\n",
    "        'Spatial Lag': [\n",
    "            lag_model.pr2,\n",
    "            lag_model.logll,\n",
    "            lag_model.aic,\n",
    "            lag_model.schwarz,\n",
    "            lag_model.betas[1][0],\n",
    "            lag_model.std_err[1],\n",
    "            lag_model.rho,\n",
    "            np.nan\n",
    "        ],\n",
    "        'Spatial Error': [\n",
    "            error_model.pr2,\n",
    "            error_model.logll,\n",
    "            error_model.aic,\n",
    "            error_model.schwarz,\n",
    "            error_model.betas[1][0],\n",
    "            error_model.std_err[1],\n",
    "            np.nan,\n",
    "            error_model.lam\n",
    "        ]\n",
    "    }, index=['R²/Pseudo-R²', 'Log-likelihood', 'AIC', 'BIC', \n",
    "              'Distress Coef', 'Distress SE', 'ρ (lag)', 'λ (error)'])\n",
    "    \n",
    "    print(\"\\nMODEL COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    print(comparison.round(4))\n",
    "    \n",
    "    # Likelihood ratio tests\n",
    "    lr_lag = 2 * (lag_model.logll - ols_model.logll)\n",
    "    lr_error = 2 * (error_model.logll - ols_model.logll)\n",
    "    \n",
    "    from scipy import stats\n",
    "    p_lag = stats.chi2.sf(lr_lag, 1)\n",
    "    p_error = stats.chi2.sf(lr_error, 1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LIKELIHOOD RATIO TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Spatial Lag vs OLS:\")\n",
    "    print(f\"  LR statistic: {lr_lag:.4f}\")\n",
    "    print(f\"  p-value: {p_lag:.4f}\")\n",
    "    print(f\"\\nSpatial Error vs OLS:\")\n",
    "    print(f\"  LR statistic: {lr_error:.4f}\")\n",
    "    print(f\"  p-value: {p_error:.4f}\")\n",
    "    \n",
    "    # Best model based on AIC\n",
    "    best_model = comparison.loc['AIC'].idxmin()\n",
    "    print(f\"\\nBest model by AIC: {best_model}\")\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "model_comparison = compare_models(ols1, lag1, error1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Using overdose rate instead of physical distress\n",
    "X2 = df_model_std[[\n",
    "    'od_1316_rate',  # Different pain proxy\n",
    "    'rucc',\n",
    "    'ba_plus_pct',\n",
    "    'median_income',\n",
    "    'unemp_rate',\n",
    "    'pct_65plus',\n",
    "    'pct_nonwhite'\n",
    "]].values\n",
    "\n",
    "X2_names = ['const', 'overdose_rate'] + X1_names[2:]\n",
    "\n",
    "# Fit models with overdose rate\n",
    "ols2 = OLS(y, X2, w=w, name_y=y_name, name_x=X2_names)\n",
    "lag2 = ML_Lag(y, X2, w=w, name_y=y_name, name_x=X2_names)\n",
    "\n",
    "print(\"\\nROBUSTNESS CHECK: OVERDOSE RATE AS PAIN PROXY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"OLS coefficient: {ols2.betas[1][0]:.4f} (p={ols2.t_stat[1][1]:.4f})\")\n",
    "print(f\"Spatial Lag coefficient: {lag2.betas[1][0]:.4f} (p={lag2.z_stat[1][1]:.4f})\")\n",
    "print(f\"Spatial lag ρ: {lag2.rho:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Interaction with rurality\n",
    "df_model_std['distress_x_rural'] = df_model_std['freq_phys_distress_pct'] * df_model_std['rucc']\n",
    "\n",
    "X3 = df_model_std[[\n",
    "    'freq_phys_distress_pct',\n",
    "    'rucc',\n",
    "    'distress_x_rural',  # Interaction term\n",
    "    'ba_plus_pct',\n",
    "    'median_income',\n",
    "    'unemp_rate',\n",
    "    'pct_65plus',\n",
    "    'pct_nonwhite'\n",
    "]].values\n",
    "\n",
    "X3_names = ['const', 'phys_distress', 'rucc', 'distress_x_rural'] + X1_names[3:]\n",
    "\n",
    "# Fit interaction model\n",
    "lag3 = ML_Lag(y, X3, w=w, name_y=y_name, name_x=X3_names)\n",
    "\n",
    "print(\"\\nROBUSTNESS CHECK: INTERACTION WITH RURALITY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Physical distress (main): {lag3.betas[1][0]:.4f} (p={lag3.z_stat[1][1]:.4f})\")\n",
    "print(f\"RUCC (main): {lag3.betas[2][0]:.4f} (p={lag3.z_stat[2][1]:.4f})\")\n",
    "print(f\"Interaction: {lag3.betas[3][0]:.4f} (p={lag3.z_stat[3][1]:.4f})\")\n",
    "print(f\"Spatial lag ρ: {lag3.rho:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(models_dict):\n",
    "    \"\"\"Plot coefficient comparison across models\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Extract coefficients and standard errors\n",
    "    coef_data = []\n",
    "    for name, model in models_dict.items():\n",
    "        for i, var_name in enumerate(model['var_names'][1:], 1):  # Skip constant\n",
    "            coef_data.append({\n",
    "                'Model': name,\n",
    "                'Variable': var_name,\n",
    "                'Coefficient': model['model'].betas[i][0],\n",
    "                'SE': model['model'].std_err[i],\n",
    "                'Lower': model['model'].betas[i][0] - 1.96 * model['model'].std_err[i],\n",
    "                'Upper': model['model'].betas[i][0] + 1.96 * model['model'].std_err[i]\n",
    "            })\n",
    "    \n",
    "    coef_df = pd.DataFrame(coef_data)\n",
    "    \n",
    "    # Plot 1: Physical distress coefficient across models\n",
    "    distress_coef = coef_df[coef_df['Variable'].str.contains('distress')]\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    x = range(len(distress_coef))\n",
    "    ax1.errorbar(x, distress_coef['Coefficient'], \n",
    "                 yerr=1.96*distress_coef['SE'], \n",
    "                 fmt='o', capsize=5, capthick=2, markersize=8)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(distress_coef['Model'], rotation=45)\n",
    "    ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.set_ylabel('Coefficient (95% CI)')\n",
    "    ax1.set_title('Physical Distress Effect Across Models')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: All coefficients for best model\n",
    "    best_model_coef = coef_df[coef_df['Model'] == 'Spatial Lag']\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    y_pos = range(len(best_model_coef))\n",
    "    ax2.barh(y_pos, best_model_coef['Coefficient'], xerr=1.96*best_model_coef['SE'],\n",
    "             capsize=3, color='steelblue', alpha=0.7)\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(best_model_coef['Variable'])\n",
    "    ax2.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('Standardized Coefficient (95% CI)')\n",
    "    ax2.set_title('Spatial Lag Model - All Coefficients')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(reports / 'figures/model_coefficients.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Create models dictionary\n",
    "models_for_plot = {\n",
    "    'OLS': {'model': ols1, 'var_names': X1_names},\n",
    "    'Spatial Lag': {'model': lag1, 'var_names': X1_names},\n",
    "    'Spatial Error': {'model': error1, 'var_names': X1_names}\n",
    "}\n",
    "\n",
    "plot_coefficients(models_for_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_maps(gdf, ols_model, spatial_model):\n",
    "    \"\"\"Plot residual maps to check for remaining spatial patterns\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Add residuals to geodataframe\n",
    "    gdf_plot = gdf.copy()\n",
    "    gdf_plot = gdf_plot.iloc[:len(ols_model.u)]  # Match model sample\n",
    "    gdf_plot['ols_resid'] = ols_model.u\n",
    "    gdf_plot['spatial_resid'] = spatial_model.u\n",
    "    \n",
    "    # OLS residuals\n",
    "    gdf_plot.plot(column='ols_resid', scheme='quantiles', k=5, \n",
    "                  cmap='RdBu_r', edgecolor='white', linewidth=0.1, \n",
    "                  ax=axes[0], legend=True)\n",
    "    axes[0].set_title('OLS Model Residuals')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Spatial model residuals\n",
    "    gdf_plot.plot(column='spatial_resid', scheme='quantiles', k=5,\n",
    "                  cmap='RdBu_r', edgecolor='white', linewidth=0.1,\n",
    "                  ax=axes[1], legend=True)\n",
    "    axes[1].set_title('Spatial Lag Model Residuals')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(reports / 'figures/residual_maps.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate Moran's I of residuals\n",
    "    from esda.moran import Moran\n",
    "    mi_ols = Moran(gdf_plot['ols_resid'].values, w)\n",
    "    mi_spatial = Moran(gdf_plot['spatial_resid'].values, w)\n",
    "    \n",
    "    print(\"\\nRESIDUAL SPATIAL AUTOCORRELATION\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"OLS residuals Moran's I: {mi_ols.I:.4f} (p={mi_ols.p_norm:.4f})\")\n",
    "    print(f\"Spatial Lag residuals Moran's I: {mi_spatial.I:.4f} (p={mi_spatial.p_norm:.4f})\")\n",
    "\n",
    "# plot_residual_maps(df_model_std, ols1, lag1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_results(model, model_name, gdf):\n",
    "    \"\"\"Export model results for web visualization\"\"\"\n",
    "    \n",
    "    # Add fitted values and residuals to geodataframe\n",
    "    gdf_export = gdf.iloc[:len(model.u)].copy()\n",
    "    gdf_export[f'{model_name}_fitted'] = model.predy\n",
    "    gdf_export[f'{model_name}_residual'] = model.u\n",
    "    \n",
    "    # Create results summary\n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'n_obs': model.n,\n",
    "        'coefficients': {},\n",
    "        'diagnostics': {}\n",
    "    }\n",
    "    \n",
    "    # Add coefficients\n",
    "    for i, var_name in enumerate(X1_names):\n",
    "        results['coefficients'][var_name] = {\n",
    "            'estimate': float(model.betas[i][0]),\n",
    "            'std_error': float(model.std_err[i]),\n",
    "            'z_value': float(model.z_stat[i][0]) if hasattr(model, 'z_stat') else float(model.t_stat[i][0]),\n",
    "            'p_value': float(model.z_stat[i][1]) if hasattr(model, 'z_stat') else float(model.t_stat[i][1])\n",
    "        }\n",
    "    \n",
    "    # Add diagnostics\n",
    "    if hasattr(model, 'rho'):\n",
    "        results['diagnostics']['spatial_lag_rho'] = float(model.rho)\n",
    "    if hasattr(model, 'lam'):\n",
    "        results['diagnostics']['spatial_error_lambda'] = float(model.lam)\n",
    "    \n",
    "    results['diagnostics']['log_likelihood'] = float(model.logll)\n",
    "    results['diagnostics']['aic'] = float(model.aic)\n",
    "    results['diagnostics']['r_squared'] = float(model.r2) if hasattr(model, 'r2') else float(model.pr2)\n",
    "    \n",
    "    # Save results\n",
    "    import json\n",
    "    with open(project_root / 'web' / 'assets' / f'{model_name}_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"Model results exported for {model_name}\")\n",
    "    return gdf_export\n",
    "\n",
    "# Export results\n",
    "# gdf_with_results = export_model_results(lag1, 'spatial_lag', df_model_std)\n",
    "# gdf_with_results.to_file(project_root / 'web' / 'assets' / 'counties_with_model.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}